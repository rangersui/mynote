[toc]

# accuracy

## accuracy

该accuracy就是大家熟知的最朴素的accuracy。比如我们有6个样本，其真实标签y_true为[0, 1, 3, 3, 4, 2]，但被一个模型预测为了[0, 1, 3, 4, 4, 4]，即y_pred=[0, 1, 3, 4, 4, 4]，那么该模型的accuracy=4/6=66.67%。

## binary_accuracy

binary_accuracy和accuracy最大的不同就是，它适用于2分类的情况。

```python
keras.metrics.binary_accuracy(y_true,y_pred,threshold=0.5)
```

可以看到binary_accuracy的计算除了y_true和y_pred外，还有一个threshold参数，该参数默认为0.5。

比如有6个样本，其y_true为[0, 0, 0, 1, 1, 0]，y_pred为[0.2, 0.3, 0.6, 0.7, 0.8, 0.1]，那么其binary_accuracy=5/6=87.5%。具体计算方法为：

1. 将y_pred中的每个预测值和threshold对比，大于threshold的设为1，小于等于threshold的设为0，得到y_pred_new=[0, 0, 1, 1, 1, 0]；

2. 将y_true和y_pred_new代入到2.1中计算得到最终的binary_accuracy=87.5%。

## categorical_accuracy

categorical_accuracy针对的是y_true为onehot标签，y_pred为向量的情况。

比如有4个样本，其y_true为[[0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0]]，y_pred为[[0.1, 0.6, 0.3], [0.2, 0.7, 0.1], [0.3, 0.6, 0.1], [0.9, 0, 0.1]]，则其categorical_accuracy为75%。具体计算方法为：

1. 将y_true转为非onehot的形式，即y_true_new=[2, 1, 1, 0]；

2. 根据y_pred中的每个样本预测的分数得到y_pred_new=[1, 1, 1, 0]；

3. 将y_true_new和y_pred_new代入到2.1中计算得到最终的categorical_accuracy=75%。

## sparse_categorical_accuracy

和categorical_accuracy功能一样，只是其y_true为非onehot的形式。

比如有4个样本，其y_true为[2, 1, 1, 0]，y_pred为[[0.1, 0.6, 0.3], [0.2, 0.7, 0.1], [0.3, 0.6, 0.1], [0.9, 0, 0.1]]，则其categorical_accuracy为75%。具体计算方法为：

1. 根据y_pred中的每个样本预测的分数得到y_pred_new=[1, 1, 1, 0]；

2. 将y_true和y_pred_new代入到2.1中计算得到最终的categorical_accuracy=75%。

## top_k_categorical_accuracy

在categorical_accuracy的基础上加上top_k。categorical_accuracy要求样本在真值类别上的预测分数是在所有类别上预测分数的最大值，才算预测对，而top_k_categorical_accuracy只要求样本在真值类别上的预测分数排在其在所有类别上的预测分数的前k名就行。

比如有4个样本，其y_true为[[0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0]]，y_pred为[[0.3, 0.6, 0.1], [0.5, 0.4, 0.1], [0.3, 0.6, 0.1], [0.9, 0, 0.1]]，根据前面知识我们可以计算得到其categorical_accuracy=50%，但是其top_k_categorical_accuracy是多少呢？答案跟k息息相关。如果k大于或等于3，其top_k_categorical_accuracy毫无疑问是100%，因为总共就3个类别。如果k小于3，那就要计算了，比如k=2，那么top_k_categorical_accuracy=75%。具体计算方法为：

1. 将y_true转为非onehot的形式，即y_true_new=[2, 1, 1, 0]；

2. 计算y_pred的top_k的label，比如k=2时，y_pred_new = [[0, 1], [0, 1], [0, 1], [0, 2]]；

3. 根据每个样本的真实标签是否在预测标签的top_k内来统计准确率，上述4个样本为例，2不在[0, 1]内，1在[0, 1]内，1在[0, 1]内，0在[0, 2]内，4个样本总共预测对了3个，因此k=2时top_k_categorical_accuracy=75%。说明一下，Keras中计算top_k_categorical_accuracy时默认的k值为5。

## sparse_top_k_categorical_accuracy

和top_k_categorical_accuracy功能一样，只是其y_true为非onehot的形式。

比如有4个样本，其y_true为[2, 1, 1, 0]，y_pred为[[0.3, 0.6, 0.1], [0.5, 0.4, 0.1], [0.3, 0.6, 0.1], [0.9, 0, 0.1]]。计算sparse_top_k_categorical_accuracy的步骤如下：

1. 计算y_pred的top_k的label，比如k=2时，y_pred_new = [[0, 1], [0, 1], [0, 1], [0, 2]]；

2. 根据每个样本的真实标签是否在预测标签的top_k内来统计准确率，上述4个样本为例，2不在[0, 1]内，1在[0, 1]内，1在[0, 1]内，0在[0, 2]内，4个样本总共预测对了3个，因此k=2时top_k_categorical_accuracy=75%。

# F1-score

F1分数（F1-score）是分类问题的一个衡量指标。一些多分类问题的机器学习竞赛，常常将F1-score作为最终测评的方法。它是精确率和召回率的调和平均数，最大为1，最小为0。

$F_1=2\cdot\frac{precision\cdot recall}{precision+recall}$

此外还有F2分数和F0.5分数。F1分数认为召回率和精确率同等重要，F2分数认为召回率的重要程度是精确率的2倍，而F0.5分数认为召回率的重要程度是精确率的一半。计算公式为：

$F_\beta=(1+\beta^2)\cdot \frac{precision\cdot recall}{\beta^2\cdot precision+recall}$

G分数是另一种统一精确率和的召回率系统性能评估标准，G分数被定义为召回率和精确率的几何平均数。

$G=\sqrt{precision\cdot recall}$

### 召回率和精确率

实际上非常简单，**精确率**是针对我们**预测结果**而言的，它表示的是预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)，也就是
![[公式]](https://www.zhihu.com/equation?tex=P++%3D+%5Cfrac%7BTP%7D%7BTP%2BFP%7D)
而**召回率**是针对我们原来的**样本**而言的，它表示的是样本中的正例有多少被预测正确了。那也有两种可能，一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)。
![[公式]](https://www.zhihu.com/equation?tex=R+%3D+%5Cfrac%7BTP%7D%7BTP%2BFN%7D)